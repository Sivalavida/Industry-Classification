{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSI Word Embedding using K-means, Gaussian Mixture and Cosine Similarity as Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "from gensim import corpora\n",
    "from gensim.models import LsiModel\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "# from clustering_class import *\n",
    "# from new_combine_models import *\n",
    "# from DEC import *\n",
    "# from generate_word_vector import *\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "table {float:center}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "table {float:center}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(doc_list):\n",
    "    \"\"\"\n",
    "    Input  : docuemnt list\n",
    "    Purpose: preprocess text (tokenize, removing stopwords, and stemming)\n",
    "    Output : preprocessed text\n",
    "    \"\"\"\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    en_stop = set(stopwords.words('english'))# create English stop words list\n",
    "    p_stemmer = PorterStemmer()\n",
    "    processed_doc_list = []\n",
    "\n",
    "    for doc in doc_list:\n",
    "        lower_doc = doc.lower()\n",
    "        token_list = tokenizer.tokenize(lower_doc)\n",
    "        stopped_token_list = [i for i in token_list if not i in en_stop]\n",
    "        stemmed_token_list = [p_stemmer.stem(i) for i in stopped_token_list]\n",
    "        processed_doc = ' '.join(stemmed_token_list) # Untokenize\n",
    "        processed_doc_list.append(processed_doc)\n",
    "    \n",
    "    return processed_doc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('yahoo_spiders/data_out/yahoo_desc.csv', ).dropna().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Description</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Industry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ABT</td>\n",
       "      <td>Abbott Laboratories discovers, develops, manuf...</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>Medical Devices</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ACN</td>\n",
       "      <td>Accenture plc provides consulting, technology,...</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Information Technology Services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>MMM</td>\n",
       "      <td>3M Company develops, manufactures, and markets...</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Specialty Industrial Machinery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ABMD</td>\n",
       "      <td>Abiomed, Inc. engages in the research, develop...</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>Medical Devices</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ADBE</td>\n",
       "      <td>Adobe Inc. operates as a diversified software ...</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Software—Infrastructure</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index Ticker                                        Description  \\\n",
       "0      0    ABT  Abbott Laboratories discovers, develops, manuf...   \n",
       "1      1    ACN  Accenture plc provides consulting, technology,...   \n",
       "2      2    MMM  3M Company develops, manufactures, and markets...   \n",
       "3      3   ABMD  Abiomed, Inc. engages in the research, develop...   \n",
       "4      4   ADBE  Adobe Inc. operates as a diversified software ...   \n",
       "\n",
       "        Sector                         Industry  \n",
       "0   Healthcare                  Medical Devices  \n",
       "1   Technology  Information Technology Services  \n",
       "2  Industrials   Specialty Industrial Machinery  \n",
       "3   Healthcare                  Medical Devices  \n",
       "4   Technology          Software—Infrastructure  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(438, 5)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(df.Sector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(df.Industry))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Accenture plc provides consulting, technology, and outsourcing services worldwide. Its Communications, Media & Technology segment provides professional services for clients to accelerate and deliver digital transformation, develop industry-specific solutions, and enhance efficiencies and business results for communications, media, high tech, software, and platform companies. The company's Financial Services segment offers services for profitability pressures, industry consolidation, regulatory changes, and the need to continually adapt to new digital technologies for banking, capital market, and insurance industries. Its Health & Public Service segment provides consulting services and digital solutions to help clients deliver social, economic, and health outcomes for healthcare payers and providers, government departments and agencies, public service organizations, educational institutions, and non-profit organizations. The company's Products segment helps clients enhance their performance in distribution, sales, and marketing; in research and development, and manufacturing; and in business functions, such as finance, human resources, procurement, and supply chain. This segment serves clients in consumer goods, retail, and travel services industries; automotive, freight and logistics, industrial and electrical equipment, consumer durable and heavy equipment, and construction and infrastructure management companies; and pharmaceutical, medical technology, and biotechnology companies. Its Resources segment enables clients in chemicals, energy, forest products, metals and mining, and utilities industries to develop and implement strategies, improve operations, manage complex change initiatives, and integrate digital technologies. Accenture plc has alliance relationships with Amazon Web Services, Google, Microsoft, Oracle, Pegasystems, Salesforce, SAP, Workday, TradeIX, and Diebold Nixdorf, Incorporated. The company was founded in 1989 and is based in Dublin, Ireland.\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[1].Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_list = df['Description']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pre Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "preped_desc_list = preprocess_data(desc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "438"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preped_desc_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tdidf vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(438, 7263)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english', max_features= None, max_df = 0.5, smooth_idf=True)\n",
    "dtm = vectorizer.fit_transform(preped_desc_list) # dtm - Document Matrix (sparse matrix)\n",
    "dtm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| Index | Unique Words (features)\n",
    "| :- | -: | \n",
    "| Russell | 20025 |\n",
    "| SnP | 7263 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LSA Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test (Actual For loop is below)\n",
    "lsa = TruncatedSVD(200, algorithm = 'arpack')\n",
    "dtm_lsa = lsa.fit_transform(dtm)\n",
    "dtm_lsa = Normalizer(copy=False).fit_transform(dtm_lsa) # normalisae so each vector is len 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.186027</td>\n",
       "      <td>-0.063461</td>\n",
       "      <td>-0.212476</td>\n",
       "      <td>0.132797</td>\n",
       "      <td>0.086120</td>\n",
       "      <td>0.222043</td>\n",
       "      <td>0.301794</td>\n",
       "      <td>0.259920</td>\n",
       "      <td>-0.031192</td>\n",
       "      <td>0.080088</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.067338</td>\n",
       "      <td>0.004449</td>\n",
       "      <td>-0.056364</td>\n",
       "      <td>-0.038719</td>\n",
       "      <td>-0.017974</td>\n",
       "      <td>-0.009489</td>\n",
       "      <td>0.007618</td>\n",
       "      <td>0.073074</td>\n",
       "      <td>-0.008122</td>\n",
       "      <td>0.052722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.401177</td>\n",
       "      <td>-0.015788</td>\n",
       "      <td>-0.164992</td>\n",
       "      <td>-0.057852</td>\n",
       "      <td>0.110736</td>\n",
       "      <td>-0.037090</td>\n",
       "      <td>-0.000830</td>\n",
       "      <td>0.066506</td>\n",
       "      <td>-0.030720</td>\n",
       "      <td>-0.064347</td>\n",
       "      <td>...</td>\n",
       "      <td>0.126713</td>\n",
       "      <td>-0.066480</td>\n",
       "      <td>-0.001598</td>\n",
       "      <td>-0.062942</td>\n",
       "      <td>-0.011841</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>0.002961</td>\n",
       "      <td>0.006440</td>\n",
       "      <td>0.045562</td>\n",
       "      <td>-0.038511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.324800</td>\n",
       "      <td>-0.131666</td>\n",
       "      <td>-0.206526</td>\n",
       "      <td>0.105576</td>\n",
       "      <td>-0.036015</td>\n",
       "      <td>0.238173</td>\n",
       "      <td>0.060495</td>\n",
       "      <td>0.028622</td>\n",
       "      <td>-0.039046</td>\n",
       "      <td>-0.012727</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005368</td>\n",
       "      <td>0.030757</td>\n",
       "      <td>-0.042402</td>\n",
       "      <td>0.006760</td>\n",
       "      <td>-0.032632</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>-0.027574</td>\n",
       "      <td>-0.002905</td>\n",
       "      <td>-0.015595</td>\n",
       "      <td>-0.019584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.110320</td>\n",
       "      <td>-0.053520</td>\n",
       "      <td>-0.118458</td>\n",
       "      <td>-0.013129</td>\n",
       "      <td>0.035338</td>\n",
       "      <td>0.047525</td>\n",
       "      <td>0.083328</td>\n",
       "      <td>0.038494</td>\n",
       "      <td>0.032770</td>\n",
       "      <td>0.062653</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.049930</td>\n",
       "      <td>-0.051575</td>\n",
       "      <td>0.153006</td>\n",
       "      <td>-0.111204</td>\n",
       "      <td>0.006802</td>\n",
       "      <td>-0.052839</td>\n",
       "      <td>0.030731</td>\n",
       "      <td>0.022081</td>\n",
       "      <td>0.072314</td>\n",
       "      <td>0.070727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.267790</td>\n",
       "      <td>-0.002623</td>\n",
       "      <td>-0.201545</td>\n",
       "      <td>-0.078364</td>\n",
       "      <td>-0.025053</td>\n",
       "      <td>-0.240672</td>\n",
       "      <td>-0.079426</td>\n",
       "      <td>0.104835</td>\n",
       "      <td>-0.052271</td>\n",
       "      <td>-0.000145</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008892</td>\n",
       "      <td>-0.023900</td>\n",
       "      <td>-0.023031</td>\n",
       "      <td>0.017898</td>\n",
       "      <td>-0.017054</td>\n",
       "      <td>0.032710</td>\n",
       "      <td>0.074666</td>\n",
       "      <td>0.017683</td>\n",
       "      <td>0.000755</td>\n",
       "      <td>-0.039082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.186027 -0.063461 -0.212476  0.132797  0.086120  0.222043  0.301794   \n",
       "1  0.401177 -0.015788 -0.164992 -0.057852  0.110736 -0.037090 -0.000830   \n",
       "2  0.324800 -0.131666 -0.206526  0.105576 -0.036015  0.238173  0.060495   \n",
       "3  0.110320 -0.053520 -0.118458 -0.013129  0.035338  0.047525  0.083328   \n",
       "4  0.267790 -0.002623 -0.201545 -0.078364 -0.025053 -0.240672 -0.079426   \n",
       "\n",
       "        7         8         9    ...       190       191       192       193  \\\n",
       "0  0.259920 -0.031192  0.080088  ... -0.067338  0.004449 -0.056364 -0.038719   \n",
       "1  0.066506 -0.030720 -0.064347  ...  0.126713 -0.066480 -0.001598 -0.062942   \n",
       "2  0.028622 -0.039046 -0.012727  ... -0.005368  0.030757 -0.042402  0.006760   \n",
       "3  0.038494  0.032770  0.062653  ... -0.049930 -0.051575  0.153006 -0.111204   \n",
       "4  0.104835 -0.052271 -0.000145  ... -0.008892 -0.023900 -0.023031  0.017898   \n",
       "\n",
       "        194       195       196       197       198       199  \n",
       "0 -0.017974 -0.009489  0.007618  0.073074 -0.008122  0.052722  \n",
       "1 -0.011841 -0.032356  0.002961  0.006440  0.045562 -0.038511  \n",
       "2 -0.032632  0.000339 -0.027574 -0.002905 -0.015595 -0.019584  \n",
       "3  0.006802 -0.052839  0.030731  0.022081  0.072314  0.070727  \n",
       "4 -0.017054  0.032710  0.074666  0.017683  0.000755 -0.039082  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(dtm_lsa).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering Algos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NUM_INDUSTRIES = 69"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K - Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, 53,  8, 19, 43, 43, 50, 43, 52, 10,  2, 17,  3, 60, 42, 40, 48,\n",
       "       39, 27, 20, 17, 56,  3, 59, 43, 40, 17, 41, 56, 39, 64, 24, 28, 38,\n",
       "       30, 50,  2, 28,  2, 64, 26, 25, 23, 14, 67, 37,  3, 56, 56, 62, 13,\n",
       "       28, 18, 52, 23, 33,  8, 51, 63,  6, 50,  5, 25, 12, 44, 34, 39, 19,\n",
       "       16, 21, 38, 68, 26,  9, 30, 63, 24, 14, 54, 36, 34, 31, 61, 62, 38,\n",
       "        5, 60,  6, 13, 11, 46, 65,  2, 63, 56, 63,  8, 28, 31, 46, 62, 64,\n",
       "       53,  9,  9, 26, 13, 62, 26, 59, 24, 14, 25,  0, 67, 38, 37, 34, 55,\n",
       "       20, 65,  5, 10, 29, 26, 27, 40, 26, 16, 13, 13, 41, 25, 13, 62, 57,\n",
       "        1, 62, 17, 61, 35, 67, 53, 34,  6, 31, 64, 61, 62, 19, 43, 28, 17,\n",
       "       26, 21, 23, 23,  5, 17, 12, 56, 17, 15,  3, 11, 29, 35, 43, 68, 21,\n",
       "       63, 63,  4, 41,  0,  1, 41, 14,  3,  4, 20, 13, 13, 31, 22,  9, 16,\n",
       "       53, 14, 44,  2, 29, 41,  6, 29, 20, 33, 32, 43,  5, 56, 39, 27, 26,\n",
       "       47, 28, 42, 10, 58,  9, 39, 44, 67,  2, 63, 22,  1, 29, 10, 48, 30,\n",
       "        1, 53, 31, 51, 37, 18,  2, 31, 53, 38, 15, 46,  9,  6, 44, 68, 36,\n",
       "        3, 55,  9, 63, 25, 39, 11, 67, 32,  9, 20, 44, 10, 67,  9, 44, 58,\n",
       "        1, 20, 50,  2, 60, 56, 44, 13, 20, 63, 42, 26, 10, 42,  4, 31, 20,\n",
       "       41, 37, 64, 30, 65, 24, 19, 16, 10,  2, 30, 58,  3, 20, 46, 43, 47,\n",
       "        6, 22, 28,  6,  0, 16, 33, 31, 66, 32, 45, 40, 45, 17, 17, 22, 32,\n",
       "       26, 55,  6,  8, 54, 17, 34,  1, 52, 26, 68, 26,  3, 36, 56,  1, 51,\n",
       "       18, 41,  1, 63,  9, 15, 10, 16, 59, 62, 42, 26,  6,  2, 56, 15,  2,\n",
       "        7, 15, 32, 20, 38, 53,  7, 32,  6, 39, 35, 63, 50, 28, 53, 28, 28,\n",
       "        0, 25, 54, 22, 33, 15, 62,  3,  8, 61, 38, 39, 29, 62, 12, 40,  6,\n",
       "       29, 24, 24, 30, 20, 43,  9, 32, 31, 25, 44, 11, 25, 10, 57, 30, 19,\n",
       "       32, 36, 56, 63,  3,  9, 28, 37, 63, 49, 49, 55, 68, 40, 29,  5,  2,\n",
       "       30, 32, 42,  5, 39, 22, 48, 14, 41, 39,  7, 25, 24, 13, 10, 63, 39,\n",
       "        1, 30, 32, 51, 20, 17, 30, 57, 64, 53, 27, 16, 63])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# defining the kmeans function with initialization as k-means++\n",
    "kmeans = KMeans(n_clusters=NUM_INDUSTRIES, init='k-means++')\n",
    "# fitting the k means algorithm on scaled data\n",
    "kmeans.fit(dtm_lsa)\n",
    "pred = kmeans.predict(dtm_lsa)\n",
    "# pd.concat([df[['company']], pd.DataFrame(pred)], axis=1).head()\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_cluster(dtm):\n",
    "    '''\n",
    "    input: Document Matrix\n",
    "    output: list indicating clusters\n",
    "    '''\n",
    "    kmeans = KMeans(n_clusters=NUM_INDUSTRIES, init='k-means++')\n",
    "    kmeans.fit(dtm)\n",
    "    pred = kmeans.predict(dtm)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Mixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gmm_cluster(dtm):\n",
    "    '''\n",
    "    input: Document Matrix\n",
    "    output: list indicating clusters\n",
    "    '''\n",
    "    gmm = GaussianMixture(n_components=NUM_INDUSTRIES)\n",
    "    gmm.fit(dtm)\n",
    "    pred = gmm.predict(dtm)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [((1,),(2,),3), ((4,),(1458,),6)]\n",
    "\n",
    "mcorr = ((1458,), (1830,), 1.0000000000000004)\n",
    "list(filter(lambda tup: (tup[0] not in mcorr) and (tup[1] not in mcorr), x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((1,2), (4,)) in (1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(dtm):\n",
    "    '''\n",
    "    input: Doc Matrix\n",
    "    output: list of lists indicating clusters\n",
    "    '''\n",
    "    corr = np.asarray(np.asmatrix(dtm) * np.asmatrix(dtm).T)\n",
    "    L = corr.shape[0]\n",
    "    \n",
    "    cluster_corrs = []\n",
    "    for i in range(L):\n",
    "        for j in range(i+1,L):\n",
    "            corr_tuple = ((i,), (j,), corr[i][j])\n",
    "            cluster_corrs.append(corr_tuple)\n",
    "            \n",
    "    cluster_list = [(i,) for i in range(L)]\n",
    "    \n",
    "    num_iter = L - NUM_INDUSTRIES\n",
    "    for x in range(num_iter):\n",
    "        max_corr_tup = max(cluster_corrs, key = lambda tup: tup[2])\n",
    "        # filters ur max_corr_tup also\n",
    "        print(max_corr_tup)\n",
    "        cluster_corrs = list(filter(lambda tup: (tup[0] not in max_corr_tup) and (tup[1] not in max_corr_tup),cluster_corrs))\n",
    "        new_cluster = max_corr_tup[0] + max_corr_tup[1] # concatenate tups\n",
    "        cluster_list.remove(max_corr_tup[0])\n",
    "        cluster_list.remove(max_corr_tup[1])\n",
    "        for cluster in cluster_list:\n",
    "            # Similarity\n",
    "            n = len(new_cluster) * len(cluster)\n",
    "            total_similarity = 0\n",
    "            for cpy_1 in new_cluster:\n",
    "                for cpy_2 in cluster:\n",
    "                    total_similarity += corr[cpy_1][cpy_2]\n",
    "            similarity = total_similarity / n\n",
    "            corr_tuple = (new_cluster, cluster, similarity)\n",
    "            cluster_corrs.append(corr_tuple)\n",
    "        cluster_list.append(new_cluster)\n",
    "    \n",
    "    if len(cluster_list) != NUM_INDUSTRIES:\n",
    "        raise Exception()\n",
    "        \n",
    "    pred = np.full(N, -1)\n",
    "    for i in range(NUM_INDUSTRIES):\n",
    "        cluster = list(cluster_list[i])\n",
    "        pred[cluster] = [i] * len(cluster)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((299,), (301,), 1.0000000000000007)\n",
      "((400,), (401,), 1.0000000000000002)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-2adf4b59e904>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcosine_similarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtm_lsa\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-61-4ea4925fd3d0>\u001b[0m in \u001b[0;36mcosine_similarity\u001b[1;34m(dtm)\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;31m# filters ur max_corr_tup also\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_corr_tup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mcluster_corrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmax_corr_tup\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmax_corr_tup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcluster_corrs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[0mnew_cluster\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_corr_tup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmax_corr_tup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# concatenate tups\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mcluster_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_corr_tup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-61-4ea4925fd3d0>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(tup)\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;31m# filters ur max_corr_tup also\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_corr_tup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mcluster_corrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmax_corr_tup\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmax_corr_tup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcluster_corrs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[0mnew_cluster\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_corr_tup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmax_corr_tup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# concatenate tups\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mcluster_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_corr_tup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "cosine_similarity(dtm_lsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtmx = dtm_lsa\n",
    "corr = np.asarray(np.asmatrix(dtmx) * np.asmatrix(dtmx).T)\n",
    "L = corr.shape[0]\n",
    "\n",
    "cluster_corrs = []\n",
    "for i in range(L):\n",
    "    for j in range(i+1,L):\n",
    "        corr_tuple = ((i,), (j,), corr[i][j])\n",
    "        cluster_corrs.append(corr_tuple)\n",
    "\n",
    "cluster_list = [(i,) for i in range(L)]\n",
    "\n",
    "num_iter = L - NUM_INDUSTRIES\n",
    "for x in range(num_iter):\n",
    "    max_corr_tup = max(cluster_corrs, key = lambda tup: tup[2])\n",
    "    # filters ur max_corr_tup also\n",
    "    print(max_corr_tup)\n",
    "    cluster_corrs = list(filter(lambda tup: (tup[0] not in max_corr_tup) and (tup[1] not in max_corr_tup),cluster_corrs))\n",
    "    new_cluster = max_corr_tup[0] + max_corr_tup[1] # concatenate tups\n",
    "    cluster_list.remove(max_corr_tup[0])\n",
    "    cluster_list.remove(max_corr_tup[1])\n",
    "    for cluster in cluster_list:\n",
    "        # Similarity\n",
    "        n = len(new_cluster) * len(cluster)\n",
    "        total_similarity = 0\n",
    "        for cpy_1 in new_cluster:\n",
    "            for cpy_2 in cluster:\n",
    "                total_similarity += corr[cpy_1][cpy_2]\n",
    "        similarity = total_similarity / n\n",
    "        corr_tuple = (new_cluster, cluster, similarity)\n",
    "        cluster_corrs.append(corr_tuple)\n",
    "    cluster_list.append(new_cluster)\n",
    "\n",
    "if len(cluster_list) != NUM_INDUSTRIES:\n",
    "    raise Exception()\n",
    "\n",
    "pred = np.full(N, -1)\n",
    "for i in range(NUM_INDUSTRIES):\n",
    "    cluster = list(cluster_list[i])\n",
    "    pred[cluster] = [i] * len(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t(tup):\n",
    "    print((tup[0] not in max_corr_tup), (tup[1] not in max_corr_tup))\n",
    "    return (tup[0] not in max_corr_tup) and (tup[1] not in max_corr_tup)\n",
    "list(filter(t,cluster_corrs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run all Clustering algos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "cluster_dfs_list = [df[['Ticker']]]\n",
    "for k in range(200, 300, 100):\n",
    "    print(k)\n",
    "    lsa_k = TruncatedSVD(k, algorithm = 'arpack')\n",
    "    dtm_lsa_k = lsa_k.fit_transform(dtm)\n",
    "    dtm_lsa_k = Normalizer(copy=False).fit_transform(dtm_lsa_k)\n",
    "    # K-Means\n",
    "    clusters_k = kmeans_cluster(dtm_lsa_k)\n",
    "    cluster_dfs_list.append(pd.DataFrame(clusters_k, columns=['lsi_{}_kmeans'.format(str(k))]))\n",
    "    # GMM\n",
    "    clusters_k = gmm_cluster(dtm_lsa_k)\n",
    "    cluster_dfs_list.append(pd.DataFrame(clusters_k, columns=['lsi_{}_gmm'.format(str(k))]))\n",
    "    # Cosine_similarity\n",
    "    \n",
    "all_cluster = pd.concat(cluster_dfs_list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>lsi_200_kmeans</th>\n",
       "      <th>lsi_200_gmm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABT</td>\n",
       "      <td>23</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACN</td>\n",
       "      <td>39</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MMM</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABMD</td>\n",
       "      <td>10</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADBE</td>\n",
       "      <td>43</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ticker  lsi_200_kmeans  lsi_200_gmm\n",
       "0    ABT              23           34\n",
       "1    ACN              39           25\n",
       "2    MMM               1           33\n",
       "3   ABMD              10           35\n",
       "4   ADBE              43           19"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_cluster.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_data = pd.read_csv('data/price_us.csv',index_col=0)\n",
    "stock_data.index.names = ['date']\n",
    "stock_data.index = pd.to_datetime(stock_data.index,format='%Y%m%d')\n",
    "stock_data = stock_data[stock_data.columns.intersection(all_cluster['company'].values.tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>AA</th>\n",
       "      <th>AAL</th>\n",
       "      <th>AAN</th>\n",
       "      <th>AAOI</th>\n",
       "      <th>AAON</th>\n",
       "      <th>AAP</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AAT</th>\n",
       "      <th>AAWW</th>\n",
       "      <th>...</th>\n",
       "      <th>ZION</th>\n",
       "      <th>ZIOP</th>\n",
       "      <th>ZIXI</th>\n",
       "      <th>ZNGA</th>\n",
       "      <th>ZS</th>\n",
       "      <th>ZTS</th>\n",
       "      <th>ZUMZ</th>\n",
       "      <th>ZUO</th>\n",
       "      <th>ZYNE</th>\n",
       "      <th>ZYXI</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-02</th>\n",
       "      <td>38.5539</td>\n",
       "      <td>34.8453</td>\n",
       "      <td>51.0799</td>\n",
       "      <td>30.0870</td>\n",
       "      <td>10.79</td>\n",
       "      <td>21.0696</td>\n",
       "      <td>156.793</td>\n",
       "      <td>99.946</td>\n",
       "      <td>35.2148</td>\n",
       "      <td>48.42</td>\n",
       "      <td>...</td>\n",
       "      <td>25.7582</td>\n",
       "      <td>5.13</td>\n",
       "      <td>3.55</td>\n",
       "      <td>2.73</td>\n",
       "      <td>16.00</td>\n",
       "      <td>41.6883</td>\n",
       "      <td>38.21</td>\n",
       "      <td>14.00</td>\n",
       "      <td>14.00</td>\n",
       "      <td>0.175245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-05</th>\n",
       "      <td>37.8315</td>\n",
       "      <td>32.8266</td>\n",
       "      <td>51.0467</td>\n",
       "      <td>29.9691</td>\n",
       "      <td>10.65</td>\n",
       "      <td>20.3538</td>\n",
       "      <td>154.727</td>\n",
       "      <td>97.130</td>\n",
       "      <td>35.6161</td>\n",
       "      <td>46.65</td>\n",
       "      <td>...</td>\n",
       "      <td>24.7931</td>\n",
       "      <td>5.07</td>\n",
       "      <td>3.48</td>\n",
       "      <td>2.71</td>\n",
       "      <td>33.00</td>\n",
       "      <td>41.4380</td>\n",
       "      <td>38.94</td>\n",
       "      <td>20.00</td>\n",
       "      <td>16.25</td>\n",
       "      <td>0.155652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-06</th>\n",
       "      <td>37.2422</td>\n",
       "      <td>33.0679</td>\n",
       "      <td>50.2556</td>\n",
       "      <td>28.8489</td>\n",
       "      <td>10.25</td>\n",
       "      <td>20.0319</td>\n",
       "      <td>154.618</td>\n",
       "      <td>97.139</td>\n",
       "      <td>35.8952</td>\n",
       "      <td>45.66</td>\n",
       "      <td>...</td>\n",
       "      <td>23.8462</td>\n",
       "      <td>4.96</td>\n",
       "      <td>3.39</td>\n",
       "      <td>2.70</td>\n",
       "      <td>27.90</td>\n",
       "      <td>41.0338</td>\n",
       "      <td>38.46</td>\n",
       "      <td>20.60</td>\n",
       "      <td>19.32</td>\n",
       "      <td>0.145916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-07</th>\n",
       "      <td>37.7365</td>\n",
       "      <td>33.9237</td>\n",
       "      <td>50.2272</td>\n",
       "      <td>29.7235</td>\n",
       "      <td>9.85</td>\n",
       "      <td>20.2145</td>\n",
       "      <td>157.940</td>\n",
       "      <td>98.501</td>\n",
       "      <td>36.5756</td>\n",
       "      <td>46.48</td>\n",
       "      <td>...</td>\n",
       "      <td>24.0693</td>\n",
       "      <td>5.02</td>\n",
       "      <td>3.38</td>\n",
       "      <td>2.68</td>\n",
       "      <td>30.38</td>\n",
       "      <td>41.8808</td>\n",
       "      <td>40.28</td>\n",
       "      <td>20.60</td>\n",
       "      <td>24.54</td>\n",
       "      <td>0.142995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-08</th>\n",
       "      <td>38.8676</td>\n",
       "      <td>34.8892</td>\n",
       "      <td>50.8430</td>\n",
       "      <td>30.2049</td>\n",
       "      <td>9.96</td>\n",
       "      <td>20.7141</td>\n",
       "      <td>159.325</td>\n",
       "      <td>102.286</td>\n",
       "      <td>36.7937</td>\n",
       "      <td>48.21</td>\n",
       "      <td>...</td>\n",
       "      <td>24.4107</td>\n",
       "      <td>4.99</td>\n",
       "      <td>3.64</td>\n",
       "      <td>2.58</td>\n",
       "      <td>31.08</td>\n",
       "      <td>42.5257</td>\n",
       "      <td>41.40</td>\n",
       "      <td>19.55</td>\n",
       "      <td>35.14</td>\n",
       "      <td>0.141048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2852 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  A       AA      AAL      AAN   AAOI     AAON      AAP  \\\n",
       "date                                                                      \n",
       "2015-01-02  38.5539  34.8453  51.0799  30.0870  10.79  21.0696  156.793   \n",
       "2015-01-05  37.8315  32.8266  51.0467  29.9691  10.65  20.3538  154.727   \n",
       "2015-01-06  37.2422  33.0679  50.2556  28.8489  10.25  20.0319  154.618   \n",
       "2015-01-07  37.7365  33.9237  50.2272  29.7235   9.85  20.2145  157.940   \n",
       "2015-01-08  38.8676  34.8892  50.8430  30.2049   9.96  20.7141  159.325   \n",
       "\n",
       "               AAPL      AAT   AAWW  ...     ZION  ZIOP  ZIXI  ZNGA     ZS  \\\n",
       "date                                 ...                                     \n",
       "2015-01-02   99.946  35.2148  48.42  ...  25.7582  5.13  3.55  2.73  16.00   \n",
       "2015-01-05   97.130  35.6161  46.65  ...  24.7931  5.07  3.48  2.71  33.00   \n",
       "2015-01-06   97.139  35.8952  45.66  ...  23.8462  4.96  3.39  2.70  27.90   \n",
       "2015-01-07   98.501  36.5756  46.48  ...  24.0693  5.02  3.38  2.68  30.38   \n",
       "2015-01-08  102.286  36.7937  48.21  ...  24.4107  4.99  3.64  2.58  31.08   \n",
       "\n",
       "                ZTS   ZUMZ    ZUO   ZYNE      ZYXI  \n",
       "date                                                \n",
       "2015-01-02  41.6883  38.21  14.00  14.00  0.175245  \n",
       "2015-01-05  41.4380  38.94  20.00  16.25  0.155652  \n",
       "2015-01-06  41.0338  38.46  20.60  19.32  0.145916  \n",
       "2015-01-07  41.8808  40.28  20.60  24.54  0.142995  \n",
       "2015-01-08  42.5257  41.40  19.55  35.14  0.141048  \n",
       "\n",
       "[5 rows x 2852 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_data = stock_data.pct_change()\n",
    "stock_data=stock_data.stack()\n",
    "stock_data = stock_data.reset_index()\n",
    "stock_data.columns = ['date','company','return']\n",
    "stock_data = stock_data[['company','return','date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>return</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>-0.018737</td>\n",
       "      <td>2015-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AA</td>\n",
       "      <td>-0.057933</td>\n",
       "      <td>2015-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAL</td>\n",
       "      <td>-0.000650</td>\n",
       "      <td>2015-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAN</td>\n",
       "      <td>-0.003919</td>\n",
       "      <td>2015-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAOI</td>\n",
       "      <td>-0.012975</td>\n",
       "      <td>2015-01-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  company    return       date\n",
       "0       A -0.018737 2015-01-05\n",
       "1      AA -0.057933 2015-01-05\n",
       "2     AAL -0.000650 2015-01-05\n",
       "3     AAN -0.003919 2015-01-05\n",
       "4    AAOI -0.012975 2015-01-05"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sival\\Desktop\\RMI\\industry-classification-master\\industry-classification-master\\new_combine_models.py:142: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  1, thresh=ret_comp, inplace=True)\n",
      "c:\\users\\sival\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pandas\\core\\frame.py:4034: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  downcast=downcast, **kwargs)\n",
      "C:\\Users\\sival\\Desktop\\RMI\\industry-classification-master\\industry-classification-master\\new_combine_models.py:146: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  ].mean(1)\n"
     ]
    }
   ],
   "source": [
    "performance=performance_analysis(class_df=all_cluster,return_df=stock_data)\n",
    "performance.get_statistical_describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary table:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R2</th>\n",
       "      <th>proportion of right classification</th>\n",
       "      <th>classes number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lsi_200_gmm</th>\n",
       "      <td>0.434857</td>\n",
       "      <td>0.732819</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lsi_200_kmeans</th>\n",
       "      <td>0.428494</td>\n",
       "      <td>0.723001</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lsi_300_gmm</th>\n",
       "      <td>0.431955</td>\n",
       "      <td>0.729663</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lsi_300_kmeans</th>\n",
       "      <td>0.444555</td>\n",
       "      <td>0.717742</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lsi_400_gmm</th>\n",
       "      <td>0.443627</td>\n",
       "      <td>0.719846</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lsi_400_kmeans</th>\n",
       "      <td>0.438421</td>\n",
       "      <td>0.717391</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lsi_500_gmm</th>\n",
       "      <td>0.433254</td>\n",
       "      <td>0.700561</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lsi_500_kmeans</th>\n",
       "      <td>0.449381</td>\n",
       "      <td>0.731066</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lsi_600_gmm</th>\n",
       "      <td>0.435887</td>\n",
       "      <td>0.708626</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lsi_600_kmeans</th>\n",
       "      <td>0.437951</td>\n",
       "      <td>0.714236</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      R2 proportion of right classification  classes number\n",
       "lsi_200_gmm     0.434857                           0.732819            69.0\n",
       "lsi_200_kmeans  0.428494                           0.723001            69.0\n",
       "lsi_300_gmm     0.431955                           0.729663            69.0\n",
       "lsi_300_kmeans  0.444555                           0.717742            69.0\n",
       "lsi_400_gmm     0.443627                           0.719846            69.0\n",
       "lsi_400_kmeans  0.438421                           0.717391            69.0\n",
       "lsi_500_gmm     0.433254                           0.700561            69.0\n",
       "lsi_500_kmeans  0.449381                           0.731066            69.0\n",
       "lsi_600_gmm     0.435887                           0.708626            69.0\n",
       "lsi_600_kmeans  0.437951                           0.714236            69.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance.print_table().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Embedding model|R2|proportion of right classification|\n",
    "|----------------|--------|--------|\n",
    "| LSI length 200 | 0.4537 | 0.4962 |\n",
    "| LSI length 300 | 0.4459 | 0.4768 |\n",
    "| LSI length 400 | 0.4421 | 0.4072 |\n",
    "| LSI length 500 | 0.4554 | 0.4244 |\n",
    "| LSI length 600 | 0.4362 | 0.4409 |\n",
    "| LSI length 700 | 0.4407 | 0.3842 |\n",
    "| LSI length 800 | 0.4417 | 0.4921 |\n",
    "| LSI length 900 | 0.4478 | 0.4005 |\n",
    "| LSI length 1000 | 0.4403 | 0.4068 |\n",
    "| LSI length 1100 | 0.4380 | 0.3933 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- not sure why in their code, the classes number is not 69"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "performance.plot_industry_dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_df = pd.read_csv('data/russell3000_ratios.csv')\n",
    "def multiplier(num):\n",
    "    out=np.nan\n",
    "    if num[-1]=='B':\n",
    "        out=float(num[:-1])*1000\n",
    "    elif num[-1]=='T':\n",
    "        out=float(num[:-1])*1000*1000\n",
    "    elif num[-1]=='M':\n",
    "        out=float(num[:-1])\n",
    "    return out\n",
    "ratio_df['mkt_cap']=ratio_df['mkt_cap'].map(multiplier)\n",
    "ratio_df['beta'] = pd.to_numeric(ratio_df['beta'],errors='coerce')\n",
    "ratio_df['profit_m']=ratio_df['profit_m'].map(lambda x: float(x.strip('%').replace(',',''))/100 if not pd.isnull(x) else np.nan)\n",
    "ratio_df['roa']=ratio_df['roa'].map(lambda x: float(x.strip('%').replace(',',''))/100 if not pd.isnull(x) else np.nan)\n",
    "ratio_df['roe']=ratio_df['roe'].map(lambda x: float(x.strip('%').replace(',',''))/100 if not pd.isnull(x) else np.nan)\n",
    "charic_names=list(ratio_df.columns[2:])\n",
    "ratio_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_names=list(all_cluster.columns[1:])\n",
    "all_df=all_cluster.merge(ratio_df,how='inner',on='company')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Market value weighted:\n",
      "                 pb_ratio      beta  profit_m       roa       roe   average\n",
      "clustering                                                                 \n",
      "lsi_400_gmm     10.640692  0.338565  0.144305  0.052437  1.808450  2.596890\n",
      "lsi_500_kmeans   9.826530  0.300953  0.128645  0.048725  2.046703  2.470311\n",
      "lsi_200_gmm     10.232821  0.315177  0.146739  0.060368  1.020367  2.355094\n",
      "lsi_300_kmeans   8.713562  0.313041  0.131408  0.052699  2.498582  2.341858\n",
      "lsi_600_gmm      9.329555  0.288173  0.131433  0.053440  0.873638  2.135248\n",
      "lsi_200_kmeans   7.531815  0.301557  0.128854  0.062301  1.811218  1.967149\n",
      "lsi_500_gmm      6.879473  0.311960  0.141205  0.061411  1.814388  1.841687\n",
      "lsi_600_kmeans   6.865131  0.321986  0.152246  0.059960  1.803690  1.840603\n",
      "lsi_300_gmm      6.714773  0.311362  0.154679  0.044518  1.786671  1.802401\n",
      "lsi_400_kmeans   6.307048  0.308758  0.130515  0.045149  2.171495  1.792593\n"
     ]
    }
   ],
   "source": [
    "eval_df=pd.DataFrame(columns=['clustering']+charic_names)\n",
    "total_comp=all_df.shape[0]\n",
    "charic_total=[]\n",
    "for r in range(len(charic_names)):\n",
    "    charic_total.append(ratio_df['mkt_cap'].dot(ratio_df.iloc[:,r+2]))\n",
    "charic_total=charic_total/ratio_df['mkt_cap'].sum()\n",
    "cl_results=[]\n",
    "for cl in range(len(cluster_names)):\n",
    "    cl_res=[cluster_names[cl]]\n",
    "    for r in range(len(charic_names)):\n",
    "        clr_df=all_df.loc[:,[cluster_names[cl],charic_names[r],'mkt_cap']]\n",
    "        clr_df['sumpro']=clr_df[charic_names[r]]*clr_df['mkt_cap']\n",
    "        clr_df=clr_df.groupby(cluster_names[cl]).agg({charic_names[r]:'count','mkt_cap':'sum','sumpro':'sum'})\n",
    "        clr_df['sigma']=clr_df[charic_names[r]]/np.sum(clr_df[charic_names[r]])*(clr_df['sumpro']/clr_df['mkt_cap']-charic_total[r])**2\n",
    "        clr=np.sqrt(clr_df['sigma'].sum())\n",
    "        cl_res.append(clr)\n",
    "    cl_results.append(cl_res)\n",
    "eval_df=eval_df.append(pd.DataFrame(cl_results,columns=eval_df.columns))\n",
    "eval_df['average']=eval_df.mean(1)\n",
    "eval_df.set_index('clustering',inplace=True)\n",
    "eval_df=eval_df.sort_values('average', ascending=False)\n",
    "print('Market value weighted:')\n",
    "print(eval_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equal value weighted:\n",
      "                pb_ratio      beta  profit_m       roa       roe   average\n",
      "clustering                                                                \n",
      "lsi_500_kmeans  3.733019  0.411994  0.176020  0.073677  3.165244  1.511991\n",
      "lsi_400_kmeans  4.306670  0.411335  0.295937  0.070271  2.399707  1.496784\n",
      "lsi_600_kmeans  4.672141  0.407858  0.208312  0.074003  2.060186  1.484500\n",
      "lsi_300_kmeans  4.003964  0.400623  0.188819  0.071592  2.112957  1.355591\n",
      "lsi_300_gmm     3.665035  0.401511  0.264355  0.072710  2.351725  1.351067\n",
      "lsi_600_gmm     4.125774  0.394775  0.246937  0.072379  1.756900  1.319353\n",
      "lsi_500_gmm     3.674184  0.414296  0.314009  0.073091  2.068266  1.308769\n",
      "lsi_200_kmeans  3.992022  0.380000  0.236780  0.073897  1.803764  1.297293\n",
      "lsi_200_gmm     3.827782  0.401900  0.282234  0.074704  1.834449  1.284214\n",
      "lsi_400_gmm     3.816172  0.412976  0.193261  0.073064  1.740735  1.247242\n"
     ]
    }
   ],
   "source": [
    "eval_df=pd.DataFrame(columns=['clustering']+charic_names)\n",
    "total_comp=all_df.shape[0]\n",
    "charic_total=[]\n",
    "for r in range(len(charic_names)):\n",
    "    charic_total.append(ratio_df.iloc[:,r+2].mean())\n",
    "cl_results=[]\n",
    "for cl in range(len(cluster_names)):\n",
    "    cl_res=[cluster_names[cl]]\n",
    "    for r in range(len(charic_names)):\n",
    "        clr_df=all_df.loc[:,[cluster_names[cl],charic_names[r]]]\n",
    "        clr_df=clr_df.groupby(cluster_names[cl]).agg(['count','mean'])\n",
    "        clr_df=clr_df[clr_df[(charic_names[r],'count')]>=5]\n",
    "        clr_df['sigma']=clr_df[(charic_names[r],'count')]/np.sum(clr_df[(charic_names[r],'count')])*(clr_df[(charic_names[r],'mean')]-charic_total[r])**2\n",
    "        clr=np.sqrt(clr_df['sigma'].sum())\n",
    "        cl_res.append(clr)\n",
    "    cl_results.append(cl_res)\n",
    "eval_df=eval_df.append(pd.DataFrame(cl_results,columns=eval_df.columns))\n",
    "eval_df['average']=eval_df.mean(1)\n",
    "eval_df.set_index('clustering',inplace=True)\n",
    "eval_df=eval_df.sort_values('average', ascending=False)\n",
    "print('Equal value weighted:')\n",
    "print(eval_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plotting for 2D\n",
    "%pylab inline\n",
    "\n",
    "xs = [w[0] for w in dtm_lsa]\n",
    "ys = [w[1] for w in dtm_lsa]\n",
    "xs, ys\n",
    "\n",
    "figure()\n",
    "plt.scatter(xs,ys)\n",
    "xlabel('First principal component')\n",
    "ylabel('Second principal component')\n",
    "title('Plot of points against LSA principal components')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(dtm):\n",
    "    '''\n",
    "    input: Doc Matrix\n",
    "    output: list of lists indicating clusters\n",
    "    '''\n",
    "    corr = np.asarray(numpy.asmatrix(dtm_lsa) * numpy.asmatrix(dtm_lsa).T)\n",
    "    \n",
    "    L = dtm.shape[0]\n",
    "    clusters = [[i] for i in range(L)]\n",
    "    \n",
    "    while (len(clusters) != NUM_INDUSTRIES):\n",
    "        L = len(clusters)\n",
    "        max_similarity = -1\n",
    "        max_similarity_clusters = (None, None)\n",
    "        for i in range(L):\n",
    "            for j in range(i+1,L):\n",
    "                cluster_1 = clusters[i]\n",
    "                cluster_2 = clusters[j]\n",
    "                n = len(cluster_1) * len(cluster_2)\n",
    "                \n",
    "                # Similarity\n",
    "                total_similarity = 0\n",
    "                for cpy_1 in cluster_1:\n",
    "                    for cpy_2 in cluster_2:\n",
    "                        print(cpy_1, cpy_2)\n",
    "                        total_similarity += corr[cpy_1][cpy_2]\n",
    "                similarity = total_similarity / n\n",
    "                \n",
    "                if similarity > max_similarity:\n",
    "                    max_similarity = similarity \n",
    "                    max_similarity_clusters = (i, j)\n",
    "        \n",
    "        # Merge max_similarity clusters\n",
    "        cluster_merge = clusters.pop(max_similarity_clusters[1])\n",
    "        clusters[max_similarity_clusters[0]].append(cluster_merge)\n",
    "        print(L)\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
