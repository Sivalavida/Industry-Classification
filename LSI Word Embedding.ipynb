{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSI Word Embedding using K-means, Gaussian Mixture and Cosine Similarity as Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "\n",
    "from gensim import corpora\n",
    "from gensim.models import LsiModel\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "from clustering_class import *\n",
    "from new_combine_models import *\n",
    "from DEC import *\n",
    "from generate_word_vector import *\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(doc_set):\n",
    "    \"\"\"\n",
    "    Input  : docuemnt list\n",
    "    Purpose: preprocess text (tokenize, removing stopwords, and stemming)\n",
    "    Output : preprocessed text\n",
    "    \"\"\"\n",
    "    # initialize regex tokenizer\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    # create English stop words list\n",
    "    en_stop = set(stopwords.words('english'))\n",
    "    # Create p_stemmer of class PorterStemmer\n",
    "    p_stemmer = PorterStemmer()\n",
    "    # list for tokenized documents in loop\n",
    "    texts = []\n",
    "    # loop through document list\n",
    "    for i in doc_set:\n",
    "        # clean and tokenize document string\n",
    "        raw = i.lower()\n",
    "        tokens = tokenizer.tokenize(raw)\n",
    "        # remove stop words from tokens\n",
    "        stopped_tokens = [i for i in tokens if not i in en_stop]\n",
    "        # stem tokens\n",
    "        stemmed_tokens = [p_stemmer.stem(i) for i in stopped_tokens]\n",
    "        # Untokenize\n",
    "        joined_str = ' '.join(stemmed_tokens)\n",
    "        # add tokens to list\n",
    "        texts.append(joined_str)\n",
    "    \n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/Russell3000_intro.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>company</th>\n",
       "      <th>intro</th>\n",
       "      <th>segment</th>\n",
       "      <th>industry</th>\n",
       "      <th>introLen</th>\n",
       "      <th>lemma</th>\n",
       "      <th>intro_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MMM</td>\n",
       "      <td>3M Company develops, manufactures, and markets...</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Specialty Industrial Machinery</td>\n",
       "      <td>1581</td>\n",
       "      <td>['3m', 'company', 'develop', 'manufacture', 'a...</td>\n",
       "      <td>3m company develop manufacture and market vari...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ABT</td>\n",
       "      <td>Abbott Laboratories discovers, develops, manuf...</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>Medical Devices</td>\n",
       "      <td>1954</td>\n",
       "      <td>['abbott', 'laboratories', 'discover', 'develo...</td>\n",
       "      <td>abbott laboratories discover develop manufactu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ABBV</td>\n",
       "      <td>AbbVie Inc., a research-based biopharmaceutica...</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>Drug Manufacturers—General</td>\n",
       "      <td>1997</td>\n",
       "      <td>['abbvie', 'inc', 'a', 'research', 'base', 'bi...</td>\n",
       "      <td>abbvie inc a research base biopharmaceutical c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ABMD</td>\n",
       "      <td>Abiomed, Inc. engages in the research, develop...</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>Medical Devices</td>\n",
       "      <td>1182</td>\n",
       "      <td>['abiomed', 'inc', 'engage', 'in', 'the', 'res...</td>\n",
       "      <td>abiomed inc engage in the research development...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ACN</td>\n",
       "      <td>Accenture plc provides consulting, technology,...</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Information Technology Services</td>\n",
       "      <td>1989</td>\n",
       "      <td>['accenture', 'plc', 'provide', 'consult', 'te...</td>\n",
       "      <td>accenture plc provide consult technology and o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 company                                              intro  \\\n",
       "0           0     MMM  3M Company develops, manufactures, and markets...   \n",
       "1           1     ABT  Abbott Laboratories discovers, develops, manuf...   \n",
       "2           2    ABBV  AbbVie Inc., a research-based biopharmaceutica...   \n",
       "3           3    ABMD  Abiomed, Inc. engages in the research, develop...   \n",
       "4           4     ACN  Accenture plc provides consulting, technology,...   \n",
       "\n",
       "       segment                         industry  introLen  \\\n",
       "0  Industrials   Specialty Industrial Machinery      1581   \n",
       "1   Healthcare                  Medical Devices      1954   \n",
       "2   Healthcare       Drug Manufacturers—General      1997   \n",
       "3   Healthcare                  Medical Devices      1182   \n",
       "4   Technology  Information Technology Services      1989   \n",
       "\n",
       "                                               lemma  \\\n",
       "0  ['3m', 'company', 'develop', 'manufacture', 'a...   \n",
       "1  ['abbott', 'laboratories', 'discover', 'develo...   \n",
       "2  ['abbvie', 'inc', 'a', 'research', 'base', 'bi...   \n",
       "3  ['abiomed', 'inc', 'engage', 'in', 'the', 'res...   \n",
       "4  ['accenture', 'plc', 'provide', 'consult', 'te...   \n",
       "\n",
       "                                    intro_lemmatized  \n",
       "0  3m company develop manufacture and market vari...  \n",
       "1  abbott laboratories discover develop manufactu...  \n",
       "2  abbvie inc a research base biopharmaceutical c...  \n",
       "3  abiomed inc engage in the research development...  \n",
       "4  accenture plc provide consult technology and o...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2896, 8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Abbott Laboratories discovers, develops, manufactures, and sells health care products worldwide. Its Established Pharmaceutical Products segment offers branded generic pharmaceuticals for the treatment of pancreatic exocrine insufficiency; irritable bowel syndrome or biliary spasm; intrahepatic cholestasis or depressive symptom; gynecological disorder; hormone replacement therapy; dyslipidemia; hypertension; hypothyroidism; Ménière's disease and vestibular vertigo; pain, fever, and inflammation; migraine; and anti-infective clarithromycin, as well as provides influenza vaccines and products that regulate physiological rhythm of the colon. The company's Diagnostic Products segment offers core laboratory systems in the areas of immunoassay, clinical chemistry, hematology, and transfusion; molecular diagnostics systems that automates the extraction, purification, and preparation of DNA and RNA from patient samples, as well as detects and measures infectious agents; cartridges for blood analysis; rapid diagnostics systems for infectious diseases; molecular point-of-care testing for HIV, influenza A and B, RSV, and strep A; cardiometabolic test systems; drug and alcohol test systems, as well as remote patient monitoring and consumer self-test systems; and informatics and automation solutions for use in laboratories. Its Nutritional Products segment provides pediatric and adult nutritional products. The company's Medical Devices segment offers rhythm management, electrophysiology, heart failure, vascular, and structural heart devices for the treatment of cardiovascular diseases, as well as neuromodulation devices for the management of chronic pain and movement disorders. This segment also provides glucose and blood glucose monitoring systems, including test strips, sensors, data management decision software, and accessories for people with diabetes. The company was founded in 1888 and is headquartered in Abbott Park, Illinois.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[1].intro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_list = df['intro']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pre Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "preped_doc_list = preprocess_data(doc_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tdidf vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2896, 20025)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english', max_features= None, max_df = 0.5, smooth_idf=True)\n",
    "dtm = vectorizer.fit_transform(preped_doc_list) # dtm - Document Matrix (sparse matrix)\n",
    "dtm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 20025 unique words (features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LSA Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "lsa = TruncatedSVD(200, algorithm = 'arpack')\n",
    "dtm_lsa = lsa.fit_transform(dtm)\n",
    "dtm_lsa = Normalizer(copy=False).fit_transform(dtm_lsa) # normalisae so each vector is len 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.258696</td>\n",
       "      <td>0.343025</td>\n",
       "      <td>0.038922</td>\n",
       "      <td>-0.082137</td>\n",
       "      <td>-0.124406</td>\n",
       "      <td>0.210290</td>\n",
       "      <td>0.063098</td>\n",
       "      <td>0.021308</td>\n",
       "      <td>0.132296</td>\n",
       "      <td>-0.168311</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004256</td>\n",
       "      <td>0.095316</td>\n",
       "      <td>-0.015159</td>\n",
       "      <td>-0.003632</td>\n",
       "      <td>-0.043507</td>\n",
       "      <td>-0.015361</td>\n",
       "      <td>-0.006947</td>\n",
       "      <td>-0.035092</td>\n",
       "      <td>0.001768</td>\n",
       "      <td>-0.044589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.139145</td>\n",
       "      <td>0.281081</td>\n",
       "      <td>0.313787</td>\n",
       "      <td>-0.000777</td>\n",
       "      <td>-0.062711</td>\n",
       "      <td>0.039652</td>\n",
       "      <td>-0.014875</td>\n",
       "      <td>-0.047445</td>\n",
       "      <td>0.079307</td>\n",
       "      <td>-0.149286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025904</td>\n",
       "      <td>0.000726</td>\n",
       "      <td>-0.047903</td>\n",
       "      <td>-0.013403</td>\n",
       "      <td>0.007489</td>\n",
       "      <td>-0.031114</td>\n",
       "      <td>-0.033641</td>\n",
       "      <td>0.047959</td>\n",
       "      <td>-0.088865</td>\n",
       "      <td>0.007064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.074533</td>\n",
       "      <td>0.159242</td>\n",
       "      <td>0.523024</td>\n",
       "      <td>0.180128</td>\n",
       "      <td>-0.020108</td>\n",
       "      <td>0.031197</td>\n",
       "      <td>-0.007244</td>\n",
       "      <td>-0.012393</td>\n",
       "      <td>0.025801</td>\n",
       "      <td>0.007321</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.040500</td>\n",
       "      <td>-0.055750</td>\n",
       "      <td>0.126388</td>\n",
       "      <td>-0.041882</td>\n",
       "      <td>-0.000613</td>\n",
       "      <td>-0.007205</td>\n",
       "      <td>-0.039796</td>\n",
       "      <td>0.001773</td>\n",
       "      <td>-0.014341</td>\n",
       "      <td>-0.056609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.081596</td>\n",
       "      <td>0.196524</td>\n",
       "      <td>0.112854</td>\n",
       "      <td>-0.003735</td>\n",
       "      <td>-0.075644</td>\n",
       "      <td>0.007277</td>\n",
       "      <td>0.031386</td>\n",
       "      <td>-0.063440</td>\n",
       "      <td>-0.006427</td>\n",
       "      <td>-0.129971</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.163261</td>\n",
       "      <td>-0.077003</td>\n",
       "      <td>0.038435</td>\n",
       "      <td>0.031072</td>\n",
       "      <td>-0.005973</td>\n",
       "      <td>0.044340</td>\n",
       "      <td>-0.062861</td>\n",
       "      <td>0.036373</td>\n",
       "      <td>-0.032168</td>\n",
       "      <td>-0.075726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.331573</td>\n",
       "      <td>0.416709</td>\n",
       "      <td>0.028846</td>\n",
       "      <td>-0.183862</td>\n",
       "      <td>-0.001686</td>\n",
       "      <td>-0.053099</td>\n",
       "      <td>-0.124019</td>\n",
       "      <td>-0.041981</td>\n",
       "      <td>0.095736</td>\n",
       "      <td>0.009783</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028951</td>\n",
       "      <td>-0.003283</td>\n",
       "      <td>0.018637</td>\n",
       "      <td>0.025221</td>\n",
       "      <td>-0.078516</td>\n",
       "      <td>0.014860</td>\n",
       "      <td>-0.056209</td>\n",
       "      <td>0.048740</td>\n",
       "      <td>0.087338</td>\n",
       "      <td>-0.023218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.258696  0.343025  0.038922 -0.082137 -0.124406  0.210290  0.063098   \n",
       "1  0.139145  0.281081  0.313787 -0.000777 -0.062711  0.039652 -0.014875   \n",
       "2  0.074533  0.159242  0.523024  0.180128 -0.020108  0.031197 -0.007244   \n",
       "3  0.081596  0.196524  0.112854 -0.003735 -0.075644  0.007277  0.031386   \n",
       "4  0.331573  0.416709  0.028846 -0.183862 -0.001686 -0.053099 -0.124019   \n",
       "\n",
       "        7         8         9    ...       190       191       192       193  \\\n",
       "0  0.021308  0.132296 -0.168311  ...  0.004256  0.095316 -0.015159 -0.003632   \n",
       "1 -0.047445  0.079307 -0.149286  ...  0.025904  0.000726 -0.047903 -0.013403   \n",
       "2 -0.012393  0.025801  0.007321  ... -0.040500 -0.055750  0.126388 -0.041882   \n",
       "3 -0.063440 -0.006427 -0.129971  ... -0.163261 -0.077003  0.038435  0.031072   \n",
       "4 -0.041981  0.095736  0.009783  ...  0.028951 -0.003283  0.018637  0.025221   \n",
       "\n",
       "        194       195       196       197       198       199  \n",
       "0 -0.043507 -0.015361 -0.006947 -0.035092  0.001768 -0.044589  \n",
       "1  0.007489 -0.031114 -0.033641  0.047959 -0.088865  0.007064  \n",
       "2 -0.000613 -0.007205 -0.039796  0.001773 -0.014341 -0.056609  \n",
       "3 -0.005973  0.044340 -0.062861  0.036373 -0.032168 -0.075726  \n",
       "4 -0.078516  0.014860 -0.056209  0.048740  0.087338 -0.023218  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(dtm_lsa).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering Algos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NUM_INDUSTRIES = 69"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K - Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([26, 53, 34, ...,  1, 66, 38])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# defining the kmeans function with initialization as k-means++\n",
    "kmeans = KMeans(n_clusters=NUM_INDUSTRIES, init='k-means++')\n",
    "# fitting the k means algorithm on scaled data\n",
    "kmeans.fit(dtm_lsa)\n",
    "pred = kmeans.predict(dtm_lsa)\n",
    "# pd.concat([df[['company']], pd.DataFrame(pred)], axis=1).head()\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_cluster(dtm):\n",
    "    '''\n",
    "    input: Document Matrix\n",
    "    output: list indicating clusters\n",
    "    '''\n",
    "    kmeans = KMeans(n_clusters=NUM_INDUSTRIES, init='k-means++')\n",
    "    kmeans.fit(dtm)\n",
    "    pred = kmeans.predict(dtm)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Mixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gmm_cluster(dtm):\n",
    "    '''\n",
    "    input: Document Matrix\n",
    "    output: list indicating clusters\n",
    "    '''\n",
    "    gmm = GaussianMixture(n_components=NUM_INDUSTRIES)\n",
    "    gmm.fit(dtm)\n",
    "    pred = gmm.predict(dtm)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [((1,),(2,),3), ((4,),(1458,),6)]\n",
    "\n",
    "mcorr = ((1458,), (1830,), 1.0000000000000004)\n",
    "list(filter(lambda tup: (tup[0] not in mcorr) and (tup[1] not in mcorr), x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((1,2), (4,)) in (1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(dtm):\n",
    "    '''\n",
    "    input: Doc Matrix\n",
    "    output: list of lists indicating clusters\n",
    "    '''\n",
    "    corr = np.asarray(np.asmatrix(dtm) * np.asmatrix(dtm).T)\n",
    "    L = corr.shape[0]\n",
    "    \n",
    "    cluster_corrs = []\n",
    "    for i in range(L):\n",
    "        for j in range(i+1,L):\n",
    "            corr_tuple = ((i,), (j,), corr[i][j])\n",
    "            cluster_corrs.append(corr_tuple)\n",
    "            \n",
    "    cluster_list = [(i,) for i in range(L)]\n",
    "    \n",
    "    num_iter = L - NUM_INDUSTRIES\n",
    "    for x in range(num_iter):\n",
    "        max_corr_tup = max(cluster_corrs, key = lambda tup: tup[2])\n",
    "        # filters ur max_corr_tup also\n",
    "        print(max_corr_tup)\n",
    "        cluster_corrs = list(filter(lambda tup: (tup[0] not in max_corr_tup) and (tup[1] not in max_corr_tup),cluster_corrs))\n",
    "        new_cluster = max_corr_tup[0] + max_corr_tup[1] # concatenate tups\n",
    "        cluster_list.remove(max_corr_tup[0])\n",
    "        cluster_list.remove(max_corr_tup[1])\n",
    "        for cluster in cluster_list:\n",
    "            # Similarity\n",
    "            n = len(new_cluster) * len(cluster)\n",
    "            total_similarity = 0\n",
    "            for cpy_1 in new_cluster:\n",
    "                for cpy_2 in cluster:\n",
    "                    total_similarity += corr[cpy_1][cpy_2]\n",
    "            similarity = total_similarity / n\n",
    "            corr_tuple = (new_cluster, cluster, similarity)\n",
    "            cluster_corrs.append(corr_tuple)\n",
    "        cluster_list.append(new_cluster)\n",
    "    \n",
    "    if len(cluster_list) != NUM_INDUSTRIES:\n",
    "        raise Exception()\n",
    "        \n",
    "    pred = np.full(N, -1)\n",
    "    for i in range(NUM_INDUSTRIES):\n",
    "        cluster = list(cluster_list[i])\n",
    "        pred[cluster] = [i] * len(cluster)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity(dtm_lsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtmx = dtm_lsa\n",
    "corr = np.asarray(np.asmatrix(dtmx) * np.asmatrix(dtmx).T)\n",
    "L = corr.shape[0]\n",
    "\n",
    "cluster_corrs = []\n",
    "for i in range(L):\n",
    "    for j in range(i+1,L):\n",
    "        corr_tuple = ((i,), (j,), corr[i][j])\n",
    "        cluster_corrs.append(corr_tuple)\n",
    "\n",
    "cluster_list = [(i,) for i in range(L)]\n",
    "\n",
    "num_iter = L - NUM_INDUSTRIES\n",
    "for x in range(num_iter):\n",
    "    max_corr_tup = max(cluster_corrs, key = lambda tup: tup[2])\n",
    "    # filters ur max_corr_tup also\n",
    "    print(max_corr_tup)\n",
    "    cluster_corrs = list(filter(lambda tup: (tup[0] not in max_corr_tup) and (tup[1] not in max_corr_tup),cluster_corrs))\n",
    "    new_cluster = max_corr_tup[0] + max_corr_tup[1] # concatenate tups\n",
    "    cluster_list.remove(max_corr_tup[0])\n",
    "    cluster_list.remove(max_corr_tup[1])\n",
    "    for cluster in cluster_list:\n",
    "        # Similarity\n",
    "        n = len(new_cluster) * len(cluster)\n",
    "        total_similarity = 0\n",
    "        for cpy_1 in new_cluster:\n",
    "            for cpy_2 in cluster:\n",
    "                total_similarity += corr[cpy_1][cpy_2]\n",
    "        similarity = total_similarity / n\n",
    "        corr_tuple = (new_cluster, cluster, similarity)\n",
    "        cluster_corrs.append(corr_tuple)\n",
    "    cluster_list.append(new_cluster)\n",
    "\n",
    "if len(cluster_list) != NUM_INDUSTRIES:\n",
    "    raise Exception()\n",
    "\n",
    "pred = np.full(N, -1)\n",
    "for i in range(NUM_INDUSTRIES):\n",
    "    cluster = list(cluster_list[i])\n",
    "    pred[cluster] = [i] * len(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t(tup):\n",
    "    print((tup[0] not in max_corr_tup), (tup[1] not in max_corr_tup))\n",
    "    return (tup[0] not in max_corr_tup) and (tup[1] not in max_corr_tup)\n",
    "list(filter(t,cluster_corrs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stock Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'all_dfs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-6855bbf5c48f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;31m# Cosine_similarity\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mall_cluster\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_dfs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'all_dfs' is not defined"
     ]
    }
   ],
   "source": [
    "cluster_dfs_list = [df[['company']]]\n",
    "for k in range(200, 700, 100):\n",
    "    print(k)\n",
    "    lsa_k = TruncatedSVD(k, algorithm = 'arpack')\n",
    "    dtm_lsa_k = lsa_k.fit_transform(dtm)\n",
    "    dtm_lsa_k = Normalizer(copy=False).fit_transform(dtm_lsa_k)\n",
    "    # K-Means\n",
    "    clusters_k = kmeans_cluster(dtm_lsa_k)\n",
    "    cluster_dfs_list.append(pd.DataFrame(clusters_k, columns=['lsi_{}_kmeans'.format(str(k))]))\n",
    "    # GMM\n",
    "    clusters_k = gmm_cluster(dtm_lsa_k)\n",
    "    cluster_dfs_list.append(pd.DataFrame(clusters_k, columns=['lsi_{}_gmm'.format(str(k))]))\n",
    "    # Cosine_similarity\n",
    "    \n",
    "all_cluster = pd.concat(all_dfs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>lsi_200_kmeans</th>\n",
       "      <th>lsi_200_gmm</th>\n",
       "      <th>lsi_300_kmeans</th>\n",
       "      <th>lsi_300_gmm</th>\n",
       "      <th>lsi_400_kmeans</th>\n",
       "      <th>lsi_400_gmm</th>\n",
       "      <th>lsi_500_kmeans</th>\n",
       "      <th>lsi_500_gmm</th>\n",
       "      <th>lsi_600_kmeans</th>\n",
       "      <th>lsi_600_gmm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MMM</td>\n",
       "      <td>68</td>\n",
       "      <td>62</td>\n",
       "      <td>65</td>\n",
       "      <td>28</td>\n",
       "      <td>50</td>\n",
       "      <td>9</td>\n",
       "      <td>52</td>\n",
       "      <td>28</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABT</td>\n",
       "      <td>58</td>\n",
       "      <td>57</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>32</td>\n",
       "      <td>42</td>\n",
       "      <td>49</td>\n",
       "      <td>37</td>\n",
       "      <td>23</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABBV</td>\n",
       "      <td>12</td>\n",
       "      <td>64</td>\n",
       "      <td>63</td>\n",
       "      <td>53</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>67</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABMD</td>\n",
       "      <td>41</td>\n",
       "      <td>15</td>\n",
       "      <td>62</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>66</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>43</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACN</td>\n",
       "      <td>11</td>\n",
       "      <td>53</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>67</td>\n",
       "      <td>41</td>\n",
       "      <td>34</td>\n",
       "      <td>19</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  company  lsi_200_kmeans  lsi_200_gmm  lsi_300_kmeans  lsi_300_gmm  \\\n",
       "0     MMM              68           62              65           28   \n",
       "1     ABT              58           57              52           52   \n",
       "2    ABBV              12           64              63           53   \n",
       "3    ABMD              41           15              62            2   \n",
       "4     ACN              11           53              17            3   \n",
       "\n",
       "   lsi_400_kmeans  lsi_400_gmm  lsi_500_kmeans  lsi_500_gmm  lsi_600_kmeans  \\\n",
       "0              50            9              52           28              25   \n",
       "1              32           42              49           37              23   \n",
       "2              10            8              23            9              67   \n",
       "3              37           66              17           15              43   \n",
       "4              67           41              34           19              24   \n",
       "\n",
       "   lsi_600_gmm  \n",
       "0           15  \n",
       "1           62  \n",
       "2           21  \n",
       "3            8  \n",
       "4            9  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_cluster.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_data = pd.read_csv('data/price_us.csv',index_col=0)\n",
    "stock_data.index.names = ['date']\n",
    "stock_data.index = pd.to_datetime(stock_data.index,format='%Y%m%d')\n",
    "stock_data = stock_data[stock_data.columns.intersection(all_cluster['company'].values.tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>AA</th>\n",
       "      <th>AAL</th>\n",
       "      <th>AAN</th>\n",
       "      <th>AAOI</th>\n",
       "      <th>AAON</th>\n",
       "      <th>AAP</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AAT</th>\n",
       "      <th>AAWW</th>\n",
       "      <th>...</th>\n",
       "      <th>ZION</th>\n",
       "      <th>ZIOP</th>\n",
       "      <th>ZIXI</th>\n",
       "      <th>ZNGA</th>\n",
       "      <th>ZS</th>\n",
       "      <th>ZTS</th>\n",
       "      <th>ZUMZ</th>\n",
       "      <th>ZUO</th>\n",
       "      <th>ZYNE</th>\n",
       "      <th>ZYXI</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-02</th>\n",
       "      <td>38.5539</td>\n",
       "      <td>34.8453</td>\n",
       "      <td>51.0799</td>\n",
       "      <td>30.0870</td>\n",
       "      <td>10.79</td>\n",
       "      <td>21.0696</td>\n",
       "      <td>156.793</td>\n",
       "      <td>99.946</td>\n",
       "      <td>35.2148</td>\n",
       "      <td>48.42</td>\n",
       "      <td>...</td>\n",
       "      <td>25.7582</td>\n",
       "      <td>5.13</td>\n",
       "      <td>3.55</td>\n",
       "      <td>2.73</td>\n",
       "      <td>16.00</td>\n",
       "      <td>41.6883</td>\n",
       "      <td>38.21</td>\n",
       "      <td>14.00</td>\n",
       "      <td>14.00</td>\n",
       "      <td>0.175245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-05</th>\n",
       "      <td>37.8315</td>\n",
       "      <td>32.8266</td>\n",
       "      <td>51.0467</td>\n",
       "      <td>29.9691</td>\n",
       "      <td>10.65</td>\n",
       "      <td>20.3538</td>\n",
       "      <td>154.727</td>\n",
       "      <td>97.130</td>\n",
       "      <td>35.6161</td>\n",
       "      <td>46.65</td>\n",
       "      <td>...</td>\n",
       "      <td>24.7931</td>\n",
       "      <td>5.07</td>\n",
       "      <td>3.48</td>\n",
       "      <td>2.71</td>\n",
       "      <td>33.00</td>\n",
       "      <td>41.4380</td>\n",
       "      <td>38.94</td>\n",
       "      <td>20.00</td>\n",
       "      <td>16.25</td>\n",
       "      <td>0.155652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-06</th>\n",
       "      <td>37.2422</td>\n",
       "      <td>33.0679</td>\n",
       "      <td>50.2556</td>\n",
       "      <td>28.8489</td>\n",
       "      <td>10.25</td>\n",
       "      <td>20.0319</td>\n",
       "      <td>154.618</td>\n",
       "      <td>97.139</td>\n",
       "      <td>35.8952</td>\n",
       "      <td>45.66</td>\n",
       "      <td>...</td>\n",
       "      <td>23.8462</td>\n",
       "      <td>4.96</td>\n",
       "      <td>3.39</td>\n",
       "      <td>2.70</td>\n",
       "      <td>27.90</td>\n",
       "      <td>41.0338</td>\n",
       "      <td>38.46</td>\n",
       "      <td>20.60</td>\n",
       "      <td>19.32</td>\n",
       "      <td>0.145916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-07</th>\n",
       "      <td>37.7365</td>\n",
       "      <td>33.9237</td>\n",
       "      <td>50.2272</td>\n",
       "      <td>29.7235</td>\n",
       "      <td>9.85</td>\n",
       "      <td>20.2145</td>\n",
       "      <td>157.940</td>\n",
       "      <td>98.501</td>\n",
       "      <td>36.5756</td>\n",
       "      <td>46.48</td>\n",
       "      <td>...</td>\n",
       "      <td>24.0693</td>\n",
       "      <td>5.02</td>\n",
       "      <td>3.38</td>\n",
       "      <td>2.68</td>\n",
       "      <td>30.38</td>\n",
       "      <td>41.8808</td>\n",
       "      <td>40.28</td>\n",
       "      <td>20.60</td>\n",
       "      <td>24.54</td>\n",
       "      <td>0.142995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-08</th>\n",
       "      <td>38.8676</td>\n",
       "      <td>34.8892</td>\n",
       "      <td>50.8430</td>\n",
       "      <td>30.2049</td>\n",
       "      <td>9.96</td>\n",
       "      <td>20.7141</td>\n",
       "      <td>159.325</td>\n",
       "      <td>102.286</td>\n",
       "      <td>36.7937</td>\n",
       "      <td>48.21</td>\n",
       "      <td>...</td>\n",
       "      <td>24.4107</td>\n",
       "      <td>4.99</td>\n",
       "      <td>3.64</td>\n",
       "      <td>2.58</td>\n",
       "      <td>31.08</td>\n",
       "      <td>42.5257</td>\n",
       "      <td>41.40</td>\n",
       "      <td>19.55</td>\n",
       "      <td>35.14</td>\n",
       "      <td>0.141048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2852 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  A       AA      AAL      AAN   AAOI     AAON      AAP  \\\n",
       "date                                                                      \n",
       "2015-01-02  38.5539  34.8453  51.0799  30.0870  10.79  21.0696  156.793   \n",
       "2015-01-05  37.8315  32.8266  51.0467  29.9691  10.65  20.3538  154.727   \n",
       "2015-01-06  37.2422  33.0679  50.2556  28.8489  10.25  20.0319  154.618   \n",
       "2015-01-07  37.7365  33.9237  50.2272  29.7235   9.85  20.2145  157.940   \n",
       "2015-01-08  38.8676  34.8892  50.8430  30.2049   9.96  20.7141  159.325   \n",
       "\n",
       "               AAPL      AAT   AAWW  ...     ZION  ZIOP  ZIXI  ZNGA     ZS  \\\n",
       "date                                 ...                                     \n",
       "2015-01-02   99.946  35.2148  48.42  ...  25.7582  5.13  3.55  2.73  16.00   \n",
       "2015-01-05   97.130  35.6161  46.65  ...  24.7931  5.07  3.48  2.71  33.00   \n",
       "2015-01-06   97.139  35.8952  45.66  ...  23.8462  4.96  3.39  2.70  27.90   \n",
       "2015-01-07   98.501  36.5756  46.48  ...  24.0693  5.02  3.38  2.68  30.38   \n",
       "2015-01-08  102.286  36.7937  48.21  ...  24.4107  4.99  3.64  2.58  31.08   \n",
       "\n",
       "                ZTS   ZUMZ    ZUO   ZYNE      ZYXI  \n",
       "date                                                \n",
       "2015-01-02  41.6883  38.21  14.00  14.00  0.175245  \n",
       "2015-01-05  41.4380  38.94  20.00  16.25  0.155652  \n",
       "2015-01-06  41.0338  38.46  20.60  19.32  0.145916  \n",
       "2015-01-07  41.8808  40.28  20.60  24.54  0.142995  \n",
       "2015-01-08  42.5257  41.40  19.55  35.14  0.141048  \n",
       "\n",
       "[5 rows x 2852 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_data = stock_data.pct_change()\n",
    "stock_data=stock_data.stack()\n",
    "stock_data = stock_data.reset_index()\n",
    "stock_data.columns = ['date','company','return']\n",
    "stock_data = stock_data[['company','return','date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>return</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>-0.018737</td>\n",
       "      <td>2015-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AA</td>\n",
       "      <td>-0.057933</td>\n",
       "      <td>2015-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAL</td>\n",
       "      <td>-0.000650</td>\n",
       "      <td>2015-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAN</td>\n",
       "      <td>-0.003919</td>\n",
       "      <td>2015-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAOI</td>\n",
       "      <td>-0.012975</td>\n",
       "      <td>2015-01-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  company    return       date\n",
       "0       A -0.018737 2015-01-05\n",
       "1      AA -0.057933 2015-01-05\n",
       "2     AAL -0.000650 2015-01-05\n",
       "3     AAN -0.003919 2015-01-05\n",
       "4    AAOI -0.012975 2015-01-05"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sival\\Desktop\\RMI\\industry-classification-master\\industry-classification-master\\new_combine_models.py:142: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  1, thresh=ret_comp, inplace=True)\n",
      "c:\\users\\sival\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pandas\\core\\frame.py:4034: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  downcast=downcast, **kwargs)\n",
      "C:\\Users\\sival\\Desktop\\RMI\\industry-classification-master\\industry-classification-master\\new_combine_models.py:146: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  ].mean(1)\n"
     ]
    }
   ],
   "source": [
    "performance=performance_analysis(class_df=all_cluster,return_df=stock_data)\n",
    "performance.get_statistical_describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary table:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R2</th>\n",
       "      <th>proportion of right classification</th>\n",
       "      <th>classes number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lsi_200_gmm</th>\n",
       "      <td>0.434857</td>\n",
       "      <td>0.732819</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lsi_200_kmeans</th>\n",
       "      <td>0.428494</td>\n",
       "      <td>0.723001</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lsi_300_gmm</th>\n",
       "      <td>0.431955</td>\n",
       "      <td>0.729663</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lsi_300_kmeans</th>\n",
       "      <td>0.444555</td>\n",
       "      <td>0.717742</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lsi_400_gmm</th>\n",
       "      <td>0.443627</td>\n",
       "      <td>0.719846</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lsi_400_kmeans</th>\n",
       "      <td>0.438421</td>\n",
       "      <td>0.717391</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lsi_500_gmm</th>\n",
       "      <td>0.433254</td>\n",
       "      <td>0.700561</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lsi_500_kmeans</th>\n",
       "      <td>0.449381</td>\n",
       "      <td>0.731066</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lsi_600_gmm</th>\n",
       "      <td>0.435887</td>\n",
       "      <td>0.708626</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lsi_600_kmeans</th>\n",
       "      <td>0.437951</td>\n",
       "      <td>0.714236</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      R2 proportion of right classification  classes number\n",
       "lsi_200_gmm     0.434857                           0.732819            69.0\n",
       "lsi_200_kmeans  0.428494                           0.723001            69.0\n",
       "lsi_300_gmm     0.431955                           0.729663            69.0\n",
       "lsi_300_kmeans  0.444555                           0.717742            69.0\n",
       "lsi_400_gmm     0.443627                           0.719846            69.0\n",
       "lsi_400_kmeans  0.438421                           0.717391            69.0\n",
       "lsi_500_gmm     0.433254                           0.700561            69.0\n",
       "lsi_500_kmeans  0.449381                           0.731066            69.0\n",
       "lsi_600_gmm     0.435887                           0.708626            69.0\n",
       "lsi_600_kmeans  0.437951                           0.714236            69.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance.print_table().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| LSI length 200 | 0.4537 | 0.4962 |\n",
    "|----------------|--------|--------|\n",
    "| LSI length 300 | 0.4459 | 0.4768 |\n",
    "|----------------|--------|--------|\n",
    "| LSI length 400 | 0.4421 | 0.4072 |\n",
    "|----------------|--------|--------|\n",
    "| LSI length 500 | 0.4554 | 0.4244 |\n",
    "|----------------|--------|--------|\n",
    "| LSI length 600 | 0.4362 | 0.4409 |\n",
    "|----------------|--------|--------|\n",
    "| LSI length 700 | 0.4407 | 0.3842 |\n",
    "|----------------|--------|--------|\n",
    "| LSI length 800 | 0.4417 | 0.4921 |\n",
    "|----------------|--------|--------|\n",
    "| LSI length 900 | 0.4478 | 0.4005 |\n",
    "|----------------|--------|--------|\n",
    "| LSI length 1000 | 0.4403 | 0.4068 |\n",
    "|----------------|--------|--------|\n",
    "| LSI length 1100 | 0.4380 | 0.3933 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| This | is   |\n",
    "|------|------|\n",
    "|   a  | table|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- not sure why in their code, the classes number is not 69"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "performance.plot_industry_dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_df = pd.read_csv('data/russell3000_ratios.csv')\n",
    "def multiplier(num):\n",
    "    out=np.nan\n",
    "    if num[-1]=='B':\n",
    "        out=float(num[:-1])*1000\n",
    "    elif num[-1]=='T':\n",
    "        out=float(num[:-1])*1000*1000\n",
    "    elif num[-1]=='M':\n",
    "        out=float(num[:-1])\n",
    "    return out\n",
    "ratio_df['mkt_cap']=ratio_df['mkt_cap'].map(multiplier)\n",
    "ratio_df['beta'] = pd.to_numeric(ratio_df['beta'],errors='coerce')\n",
    "ratio_df['profit_m']=ratio_df['profit_m'].map(lambda x: float(x.strip('%').replace(',',''))/100 if not pd.isnull(x) else np.nan)\n",
    "ratio_df['roa']=ratio_df['roa'].map(lambda x: float(x.strip('%').replace(',',''))/100 if not pd.isnull(x) else np.nan)\n",
    "ratio_df['roe']=ratio_df['roe'].map(lambda x: float(x.strip('%').replace(',',''))/100 if not pd.isnull(x) else np.nan)\n",
    "charic_names=list(ratio_df.columns[2:])\n",
    "ratio_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_names=list(all_cluster.columns[1:])\n",
    "all_df=all_cluster.merge(ratio_df,how='inner',on='company')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Market value weighted:\n",
      "                 pb_ratio      beta  profit_m       roa       roe   average\n",
      "clustering                                                                 \n",
      "lsi_400_gmm     10.640692  0.338565  0.144305  0.052437  1.808450  2.596890\n",
      "lsi_500_kmeans   9.826530  0.300953  0.128645  0.048725  2.046703  2.470311\n",
      "lsi_200_gmm     10.232821  0.315177  0.146739  0.060368  1.020367  2.355094\n",
      "lsi_300_kmeans   8.713562  0.313041  0.131408  0.052699  2.498582  2.341858\n",
      "lsi_600_gmm      9.329555  0.288173  0.131433  0.053440  0.873638  2.135248\n",
      "lsi_200_kmeans   7.531815  0.301557  0.128854  0.062301  1.811218  1.967149\n",
      "lsi_500_gmm      6.879473  0.311960  0.141205  0.061411  1.814388  1.841687\n",
      "lsi_600_kmeans   6.865131  0.321986  0.152246  0.059960  1.803690  1.840603\n",
      "lsi_300_gmm      6.714773  0.311362  0.154679  0.044518  1.786671  1.802401\n",
      "lsi_400_kmeans   6.307048  0.308758  0.130515  0.045149  2.171495  1.792593\n"
     ]
    }
   ],
   "source": [
    "eval_df=pd.DataFrame(columns=['clustering']+charic_names)\n",
    "total_comp=all_df.shape[0]\n",
    "charic_total=[]\n",
    "for r in range(len(charic_names)):\n",
    "    charic_total.append(ratio_df['mkt_cap'].dot(ratio_df.iloc[:,r+2]))\n",
    "charic_total=charic_total/ratio_df['mkt_cap'].sum()\n",
    "cl_results=[]\n",
    "for cl in range(len(cluster_names)):\n",
    "    cl_res=[cluster_names[cl]]\n",
    "    for r in range(len(charic_names)):\n",
    "        clr_df=all_df.loc[:,[cluster_names[cl],charic_names[r],'mkt_cap']]\n",
    "        clr_df['sumpro']=clr_df[charic_names[r]]*clr_df['mkt_cap']\n",
    "        clr_df=clr_df.groupby(cluster_names[cl]).agg({charic_names[r]:'count','mkt_cap':'sum','sumpro':'sum'})\n",
    "        clr_df['sigma']=clr_df[charic_names[r]]/np.sum(clr_df[charic_names[r]])*(clr_df['sumpro']/clr_df['mkt_cap']-charic_total[r])**2\n",
    "        clr=np.sqrt(clr_df['sigma'].sum())\n",
    "        cl_res.append(clr)\n",
    "    cl_results.append(cl_res)\n",
    "eval_df=eval_df.append(pd.DataFrame(cl_results,columns=eval_df.columns))\n",
    "eval_df['average']=eval_df.mean(1)\n",
    "eval_df.set_index('clustering',inplace=True)\n",
    "eval_df=eval_df.sort_values('average', ascending=False)\n",
    "print('Market value weighted:')\n",
    "print(eval_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equal value weighted:\n",
      "                pb_ratio      beta  profit_m       roa       roe   average\n",
      "clustering                                                                \n",
      "lsi_500_kmeans  3.733019  0.411994  0.176020  0.073677  3.165244  1.511991\n",
      "lsi_400_kmeans  4.306670  0.411335  0.295937  0.070271  2.399707  1.496784\n",
      "lsi_600_kmeans  4.672141  0.407858  0.208312  0.074003  2.060186  1.484500\n",
      "lsi_300_kmeans  4.003964  0.400623  0.188819  0.071592  2.112957  1.355591\n",
      "lsi_300_gmm     3.665035  0.401511  0.264355  0.072710  2.351725  1.351067\n",
      "lsi_600_gmm     4.125774  0.394775  0.246937  0.072379  1.756900  1.319353\n",
      "lsi_500_gmm     3.674184  0.414296  0.314009  0.073091  2.068266  1.308769\n",
      "lsi_200_kmeans  3.992022  0.380000  0.236780  0.073897  1.803764  1.297293\n",
      "lsi_200_gmm     3.827782  0.401900  0.282234  0.074704  1.834449  1.284214\n",
      "lsi_400_gmm     3.816172  0.412976  0.193261  0.073064  1.740735  1.247242\n"
     ]
    }
   ],
   "source": [
    "eval_df=pd.DataFrame(columns=['clustering']+charic_names)\n",
    "total_comp=all_df.shape[0]\n",
    "charic_total=[]\n",
    "for r in range(len(charic_names)):\n",
    "    charic_total.append(ratio_df.iloc[:,r+2].mean())\n",
    "cl_results=[]\n",
    "for cl in range(len(cluster_names)):\n",
    "    cl_res=[cluster_names[cl]]\n",
    "    for r in range(len(charic_names)):\n",
    "        clr_df=all_df.loc[:,[cluster_names[cl],charic_names[r]]]\n",
    "        clr_df=clr_df.groupby(cluster_names[cl]).agg(['count','mean'])\n",
    "        clr_df=clr_df[clr_df[(charic_names[r],'count')]>=5]\n",
    "        clr_df['sigma']=clr_df[(charic_names[r],'count')]/np.sum(clr_df[(charic_names[r],'count')])*(clr_df[(charic_names[r],'mean')]-charic_total[r])**2\n",
    "        clr=np.sqrt(clr_df['sigma'].sum())\n",
    "        cl_res.append(clr)\n",
    "    cl_results.append(cl_res)\n",
    "eval_df=eval_df.append(pd.DataFrame(cl_results,columns=eval_df.columns))\n",
    "eval_df['average']=eval_df.mean(1)\n",
    "eval_df.set_index('clustering',inplace=True)\n",
    "eval_df=eval_df.sort_values('average', ascending=False)\n",
    "print('Equal value weighted:')\n",
    "print(eval_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plotting for 2D\n",
    "%pylab inline\n",
    "\n",
    "xs = [w[0] for w in dtm_lsa]\n",
    "ys = [w[1] for w in dtm_lsa]\n",
    "xs, ys\n",
    "\n",
    "figure()\n",
    "plt.scatter(xs,ys)\n",
    "xlabel('First principal component')\n",
    "ylabel('Second principal component')\n",
    "title('Plot of points against LSA principal components')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(dtm):\n",
    "    '''\n",
    "    input: Doc Matrix\n",
    "    output: list of lists indicating clusters\n",
    "    '''\n",
    "    corr = np.asarray(numpy.asmatrix(dtm_lsa) * numpy.asmatrix(dtm_lsa).T)\n",
    "    \n",
    "    L = dtm.shape[0]\n",
    "    clusters = [[i] for i in range(L)]\n",
    "    \n",
    "    while (len(clusters) != NUM_INDUSTRIES):\n",
    "        L = len(clusters)\n",
    "        max_similarity = -1\n",
    "        max_similarity_clusters = (None, None)\n",
    "        for i in range(L):\n",
    "            for j in range(i+1,L):\n",
    "                cluster_1 = clusters[i]\n",
    "                cluster_2 = clusters[j]\n",
    "                n = len(cluster_1) * len(cluster_2)\n",
    "                \n",
    "                # Similarity\n",
    "                total_similarity = 0\n",
    "                for cpy_1 in cluster_1:\n",
    "                    for cpy_2 in cluster_2:\n",
    "                        print(cpy_1, cpy_2)\n",
    "                        total_similarity += corr[cpy_1][cpy_2]\n",
    "                similarity = total_similarity / n\n",
    "                \n",
    "                if similarity > max_similarity:\n",
    "                    max_similarity = similarity \n",
    "                    max_similarity_clusters = (i, j)\n",
    "        \n",
    "        # Merge max_similarity clusters\n",
    "        cluster_merge = clusters.pop(max_similarity_clusters[1])\n",
    "        clusters[max_similarity_clusters[0]].append(cluster_merge)\n",
    "        print(L)\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
